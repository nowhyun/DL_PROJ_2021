{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2ddc898",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:09:03.066261Z",
     "start_time": "2021-06-01T02:09:01.455797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training device: (device(type='cuda', index=1), 'GeForce GTX 1080 Ti')\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.style.use(\"ggplot\")\n",
    "\n",
    "from Utils.dataset import *\n",
    "from Utils.utils import *\n",
    "from Models.BertClf import * \n",
    "from Models.LstmClf import *\n",
    "from Models.ElectraClf import *\n",
    "from Models.ConvClf import *\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "# device = torch.device(\"cpu\")\n",
    "torch.cuda.set_device(device) # change allocation of current GPU\n",
    "print(f'training device: {device, torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a3d610",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:08:58.157578Z",
     "start_time": "2021-06-01T02:08:58.153856Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define signature\n",
    "\"\"\"학습 잘시킨 놈으로 다가 BILSTM, CNN, BERT, ELECTRA가져와\"\"\"\n",
    "signature_list = [\"jh_BILSTM_6M_1D_11H_7M\", \n",
    "                  \"jh_CNN_5M_31D_19H_2M\", \n",
    "                  \"jh_BERT_5M_31D_18H_42M\", \n",
    "                  \"jh_ELECTRA_5M_31D_18H_23M\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bb55695",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:09:12.663234Z",
     "start_time": "2021-06-01T02:09:12.644009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Namespace(aug=0, author='jh', batch_size=1024, data_path='./Dataset', dropout=0.5, embedding_dim=256, eps=1e-08, freeze_pretrained=0, gpu=0, hidden_dim=768, kernel_depth=500, kernel_sizes=[3, 4, 5], lr_clf=0.001, lr_pretrained=1e-05, max_epoch=40, max_len=50, model='BILSTM', num_layer=2, save=1, save_model_path='./Saved_models', save_submission_path='./Submissions', sent_embedding=0, signature='jh_BILSTM_6M_1D_11H_7M', split_ratio=1, weight_decay=0.0005),\n",
       " Namespace(aug=0, author='jh', batch_size=1024, data_path='./Dataset', dropout=0.5, embedding_dim=256, eps=1e-08, freeze_pretrained=0, gpu=0, hidden_dim=768, kernel_depth=500, kernel_sizes=[3, 4, 5], lr_clf=0.0001, lr_pretrained=1e-05, max_epoch=60, max_len=50, model='CNN', num_layer=2, save=1, save_model_path='./Saved_models', save_submission_path='./Submissions', sent_embedding=0, signature='jh_CNN_5M_31D_19H_2M', split_ratio=1, weight_decay=0.0005),\n",
       " Namespace(aug=0, author='jh', batch_size=16, data_path='./Dataset', dropout=0.5, embedding_dim=256, eps=1e-08, freeze_pretrained=0, gpu=0, hidden_dim=768, kernel_depth=500, kernel_sizes=[3, 4, 5], lr_clf=0.0001, lr_pretrained=1e-05, max_epoch=10, max_len=50, model='BERT', num_layer=2, save=1, save_model_path='./Saved_models', save_submission_path='./Submissions', sent_embedding=0, signature='jh_BERT_5M_31D_18H_42M', split_ratio=1, weight_decay=0.0005),\n",
       " Namespace(aug=0, author='jh', batch_size=16, data_path='./Dataset', dropout=0.5, embedding_dim=256, eps=1e-08, freeze_pretrained=0, gpu=0, hidden_dim=768, kernel_depth=500, kernel_sizes=[3, 4, 5], lr_clf=0.0001, lr_pretrained=1e-05, max_epoch=10, max_len=50, model='ELECTRA', num_layer=2, save=1, save_model_path='./Saved_models', save_submission_path='./Submissions', sent_embedding=0, signature='jh_ELECTRA_5M_31D_18H_23M', split_ratio=1, weight_decay=0.0005)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load options\n",
    "def load_opt(signature):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    #     opt = parser.parse_args() # in .py env\n",
    "    opt, _ = parser.parse_known_args() # in .ipynb env\n",
    "    with open('./Saved_models/' + signature + '_opt.txt', 'r') as f:\n",
    "        opt.__dict__ = json.load(f)\n",
    "    return opt\n",
    "\n",
    "opt_list = []\n",
    "for sign in signature_list:\n",
    "    opt_list.append(load_opt(sign))\n",
    "opt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a880ada",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:15:42.321515Z",
     "start_time": "2021-06-01T02:15:07.453844Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data...\n",
      "Apply the BertTokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_ids_tsr.shape: torch.Size([7805, 50])\n",
      "train_X_masks_tsr.shape: torch.Size([7805, 50])\n",
      "Tokenizing data...\n",
      "Apply the BertTokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_X_ids_tsr.shape: torch.Size([1748, 50])\n",
      "valid_X_masks_tsr.shape: torch.Size([1748, 50])\n",
      "Tokenizing data...\n",
      "Apply the BertTokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_X_ids_tsr.shape: torch.Size([4311, 50])\n",
      "test_X_masks_tsr.shape: torch.Size([4311, 50])\n",
      "num of train_loader: 7805\n",
      "num of valid_loader: 1748\n",
      "num of test_loader: 4311\n",
      "Tokenizing data...\n",
      "Apply the ElectraTokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_ids_tsr.shape: torch.Size([7805, 50])\n",
      "train_X_masks_tsr.shape: torch.Size([7805, 50])\n",
      "Tokenizing data...\n",
      "Apply the ElectraTokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_X_ids_tsr.shape: torch.Size([1748, 50])\n",
      "valid_X_masks_tsr.shape: torch.Size([1748, 50])\n",
      "Tokenizing data...\n",
      "Apply the ElectraTokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_X_ids_tsr.shape: torch.Size([4311, 50])\n",
      "test_X_masks_tsr.shape: torch.Size([4311, 50])\n",
      "num of train_loader: 7805\n",
      "num of valid_loader: 1748\n",
      "num of test_loader: 4311\n"
     ]
    }
   ],
   "source": [
    "submission_templete_df = pd.read_csv(opt_list[0].data_path +'/sample_sub.csv') # a sample submission file in the correct format\n",
    "\n",
    "_, valid_dataloader_bert, test_dataloader_bert = data_load(opt_list[0])\n",
    "_, valid_dataloader_electra, test_dataloader_electra = data_load(opt_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dac49eff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:13:55.174178Z",
     "start_time": "2021-06-01T02:13:50.176858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bilstm = LstmClassifier(opt_list[0])\n",
    "model_bilstm.to(device)\n",
    "model_save_path = str(opt_list[0].save_model_path) + \"/\" + opt_list[0].signature +'.model'\n",
    "model_bilstm.load_state_dict(torch.load(model_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be65b136",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:13:58.669628Z",
     "start_time": "2021-06-01T02:13:58.505368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn = ConvClassifier(opt_list[1])\n",
    "model_cnn.to(device)\n",
    "model_save_path = str(opt_list[1].save_model_path) + \"/\" + opt_list[1].signature +'.model'\n",
    "model_cnn.load_state_dict(torch.load(model_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c93a5b2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:14:12.950737Z",
     "start_time": "2021-06-01T02:14:08.236947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bert = BertClassifier(opt_list[2])\n",
    "model_bert.to(device)\n",
    "model_save_path = str(opt_list[2].save_model_path) + \"/\" + opt_list[2].signature +'.model'\n",
    "model_bert.load_state_dict(torch.load(model_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "052f5f81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:14:19.409652Z",
     "start_time": "2021-06-01T02:14:15.001337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_electra = ElectraClassifier(opt_list[3])\n",
    "model_electra.to(device)\n",
    "model_save_path = str(opt_list[3].save_model_path) + \"/\" + opt_list[3].signature +'.model'\n",
    "model_electra.load_state_dict(torch.load(model_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5053122",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:14:23.143071Z",
     "start_time": "2021-06-01T02:14:23.126608Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_preds(model, opt, device, test_dataloader, flag=\"valid\"):\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "\n",
    "    # For each batch in our test set...\n",
    "    for batch in test_dataloader:\n",
    "        # Load batch \n",
    "        if flag == \"valid\":\n",
    "            b_ids_tsr, b_masks_tsr, b_labels_tsr = tuple(tsr.to(device) for tsr in batch)[:3]\n",
    "        else:\n",
    "            b_ids_tsr, b_masks_tsr = tuple(tsr.to(device) for tsr in batch)[:2]\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            if opt.model in [\"BILSTM\", \"CNN\"]:\n",
    "                logits = model(b_ids_tsr)\n",
    "            else:\n",
    "                logits = model(b_ids_tsr, b_masks_tsr)\n",
    "        all_logits.append(logits)\n",
    "        if flag == \"valid\":\n",
    "            all_labels.append(b_labels_tsr)\n",
    "    \n",
    "    # Concatenate logits from each batch\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "    if flag == \"valid\":\n",
    "        all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "    # Apply softmax to calculate probabilities\n",
    "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
    "    return probs, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4c6f471",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:17:01.158269Z",
     "start_time": "2021-06-01T02:16:59.126696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bilstm_valid_probs: (1748, 5), bilstm_test_probs: (4311, 5), labels: torch.Size([1748])\n"
     ]
    }
   ],
   "source": [
    "bilstm_valid_probs, labels1 = make_preds(model_bilstm, opt_list[0], device, valid_dataloader_bert)\n",
    "bilstm_test_probs, _ = make_preds(model_bilstm, opt_list[0], device, test_dataloader_bert, flag=\"test\")\n",
    "print(f\"bilstm_valid_probs: {bilstm_valid_probs.shape}, bilstm_test_probs: {bilstm_test_probs.shape}, labels: {labels1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b3aa93b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:18:11.257474Z",
     "start_time": "2021-06-01T02:18:10.880850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_valid_probs: (1748, 5), cnn_test_probs: (4311, 5), labels: torch.Size([1748])\n"
     ]
    }
   ],
   "source": [
    "cnn_valid_probs, labels2 = make_preds(model_cnn, opt_list[1], device, valid_dataloader_bert)\n",
    "cnn_test_probs, _ = make_preds(model_cnn, opt_list[1], device, test_dataloader_bert, flag=\"test\")\n",
    "print(f\"cnn_valid_probs: {cnn_valid_probs.shape}, cnn_test_probs: {cnn_test_probs.shape}, labels: {labels2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0286eba7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:18:23.166334Z",
     "start_time": "2021-06-01T02:18:11.637149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_valid_probs: (1748, 5), bert_test_probs: (4311, 5), labels: torch.Size([1748])\n"
     ]
    }
   ],
   "source": [
    "bert_valid_probs, labels3 = make_preds(model_bert, opt_list[2], device, valid_dataloader_bert)\n",
    "bert_test_probs, _ = make_preds(model_bert, opt_list[2], device, test_dataloader_bert, flag=\"test\")\n",
    "print(f\"bert_valid_probs: {bert_valid_probs.shape}, bert_test_probs: {bert_test_probs.shape}, labels: {labels3.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df146918",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:18:40.239375Z",
     "start_time": "2021-06-01T02:18:23.168535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electra_valid_probs: (1748, 5), electra_test_probs: (4311, 5), labels: torch.Size([1748])\n"
     ]
    }
   ],
   "source": [
    "electra_valid_probs, labels4 = make_preds(model_electra, opt_list[3], device, valid_dataloader_electra)\n",
    "electra_test_probs, _ = make_preds(model_electra, opt_list[3], device, test_dataloader_electra, flag=\"test\")\n",
    "print(f\"electra_valid_probs: {electra_valid_probs.shape}, electra_test_probs: {electra_test_probs.shape}, labels: {labels4.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92e32063",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:20:19.533267Z",
     "start_time": "2021-06-01T02:20:19.500116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그래 진행시켜\n"
     ]
    }
   ],
   "source": [
    "labels1 = labels1.detach().cpu().numpy()\n",
    "labels2 = labels2.detach().cpu().numpy()\n",
    "labels3 = labels3.detach().cpu().numpy()\n",
    "labels4 = labels4.detach().cpu().numpy()\n",
    "if sum(labels1 == labels2) == sum(labels1 == labels3) & sum(labels1 == labels2) == sum(labels1 == labels4):\n",
    "    print(\"그래 진행시켜\")\n",
    "labels = labels1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d04a132f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:30:54.019835Z",
     "start_time": "2021-06-01T02:30:54.003713Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5617848970251716"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bilstm_valid_preds == labels) / len(labels) # bilstm valid acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "98b6e86c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:30:54.306331Z",
     "start_time": "2021-06-01T02:30:54.291253Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6384439359267735"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cnn_valid_preds == labels) / len(labels) # cnn valid acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49525d65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:31:15.497074Z",
     "start_time": "2021-06-01T02:31:15.481715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7551487414187643"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bert_valid_preds == labels) / len(labels) # bert valid acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8451d243",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:31:15.728489Z",
     "start_time": "2021-06-01T02:31:15.713838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7402745995423341"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(electra_valid_preds == labels) / len(labels) # electra valid acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51555ee2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:24:59.625838Z",
     "start_time": "2021-06-01T02:24:59.615591Z"
    }
   },
   "outputs": [],
   "source": [
    "# HitDifferenceRatio on valid dataset\n",
    "bilstm_valid_preds = np.argmax(bilstm_valid_probs, axis=1)\n",
    "cnn_valid_preds = np.argmax(cnn_valid_probs, axis=1)\n",
    "bert_valid_preds = np.argmax(bert_valid_probs, axis=1)\n",
    "electra_valid_preds = np.argmax(electra_valid_probs, axis=1)\n",
    "\n",
    "# (Electra, Bert), (Electra, Bilstm), (Electra, Cnn)\n",
    "def calDHR(preds1, preds2, labels=labels):    \n",
    "    union_arr = np.where((labels == preds1) | (labels == preds2))\n",
    "    intersection_arr = (np.where((labels == preds1) & (labels == preds2)))\n",
    "    sizeOfunion_int = len(union_arr[0])\n",
    "    sizeOfintersection_int = len(intersection_arr[0])\n",
    "    HDR = (sizeOfunion_int - sizeOfintersection_int) / sizeOfunion_int\n",
    "#     HDR # 높다는건 교집합이 작다 즉 서로 알려줄게 많다.\n",
    "    return HDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6658d2e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:24:59.893232Z",
     "start_time": "2021-06-01T02:24:59.886336Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2229775662814412"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calDHR(electra_valid_preds, bert_valid_preds) # electra - bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c6f21db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:25:14.381676Z",
     "start_time": "2021-06-01T02:25:14.374477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4249134948096886"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calDHR(electra_valid_preds, bilstm_valid_preds) # electra - bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "507d1977",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:25:14.580951Z",
     "start_time": "2021-06-01T02:25:14.574424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3344851416724257"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calDHR(electra_valid_preds, cnn_valid_preds) # electra - cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b457779",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:26:20.784911Z",
     "start_time": "2021-06-01T02:26:20.777886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40360610263522884"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calDHR(bert_valid_preds, bilstm_valid_preds) # bert - bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1404d50e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:26:21.065464Z",
     "start_time": "2021-06-01T02:26:21.057704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3000697836706211"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calDHR(bert_valid_preds, cnn_valid_preds) # bert - cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3aed432",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:26:21.342739Z",
     "start_time": "2021-06-01T02:26:21.335885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38117283950617287"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calDHR(bilstm_valid_preds, cnn_valid_preds) # bilstm - cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b568702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_preds(compare_valid_probs):\n",
    "    # Average on valid dataset\n",
    "    avg_preds = (electra_valid_probs + compare_valid_probs) * 0.5\n",
    "    avg_preds = np.argmax(avg_preds, axis=1)\n",
    "    print(\"avg valid acc:\", sum(avg_preds == labels) / len(labels)) # avg valid acc\n",
    "\n",
    "    # Confidence on valid dataset\n",
    "    conf_preds = []\n",
    "    for i in range(len(labels)):\n",
    "        if np.max(electra_valid_probs[i]) > np.max(compare_valid_probs[i]):\n",
    "            conf_preds.append(electra_valid_preds[i])\n",
    "        else:\n",
    "            conf_preds.append(compare_valid_probs[i])\n",
    "    conf_preds = (np.array(conf_preds))\n",
    "    print(\"conf valid acc:\", sum(conf_preds == labels) / len(labels)) # conf valid acc\n",
    "\n",
    "    # Standard Deviation on valid dataset\n",
    "    std_preds = []\n",
    "    for i in range(len(labels)):\n",
    "        if np.std(electra_valid_probs[i]) > np.std(compare_valid_probs[i]):\n",
    "            std_preds.append(electra_valid_preds[i])\n",
    "        else:\n",
    "            std_preds.append(compare_valid_probs[i])\n",
    "    std_preds = (np.array(std_preds))\n",
    "    print(\"std valid acc:\", sum(std_preds == labels) / len(labels)) # std valid acc\n",
    "\n",
    "    # top 2 on Valid dataset\n",
    "    # trial_1\n",
    "    # print(lstm_logits.shape)\n",
    "    # print(electra_logits.shape)\n",
    "    logits = []\n",
    "    for i in range(electra_valid_probs.shape[0]):\n",
    "        # print(lstm_logits[i].shape, lstm_logits[i])\n",
    "        lstm_ls = compare_valid_probs[i].tolist()\n",
    "        lstm_ls.sort(reverse=True)\n",
    "        lstm_diff = lstm_ls[0] - lstm_ls[1]\n",
    "        electra_ls = electra_logits[i].tolist()\n",
    "        electra_ls.sort(reverse=True)\n",
    "        electra_diff = electra_ls[0] - electra_ls[1]\n",
    "        if lstm_diff>electra_diff:\n",
    "            logits.append(lstm_logits[i].tolist())\n",
    "        else:\n",
    "            logits.append(electra_logits[i].tolist())\n",
    "        # print(logits)\n",
    "    logits = torch.Tensor(logits)\n",
    "    all_logits.append(logits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fb4efb49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:52:14.739703Z",
     "start_time": "2021-06-01T02:52:14.621089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg valid acc: 0.7511441647597255\n",
      "conf valid acc: 0.7408466819221968\n",
      "std valid acc: 0.7425629290617849\n"
     ]
    }
   ],
   "source": [
    "# Average on valid dataset\n",
    "avg_preds = (electra_valid_probs + bilstm_valid_probs) * 0.5\n",
    "avg_preds = np.argmax(avg_preds, axis=1)\n",
    "print(\"avg valid acc:\", sum(avg_preds == labels) / len(labels)) # avg valid acc\n",
    "\n",
    "# Confidence on valid dataset\n",
    "conf_preds = []\n",
    "for i in range(len(labels)):\n",
    "    if np.max(electra_valid_probs[i]) > np.max(bilstm_valid_probs[i]):\n",
    "        conf_preds.append(electra_valid_preds[i])\n",
    "    else:\n",
    "        conf_preds.append(bilstm_valid_preds[i])\n",
    "conf_preds = (np.array(conf_preds))\n",
    "print(\"conf valid acc:\", sum(conf_preds == labels) / len(labels)) # conf valid acc\n",
    "\n",
    "# Standard Deviation on valid dataset\n",
    "std_preds = []\n",
    "for i in range(len(labels)):\n",
    "    if np.std(electra_valid_probs[i]) > np.std(bilstm_valid_probs[i]):\n",
    "        std_preds.append(electra_valid_preds[i])\n",
    "    else:\n",
    "        std_preds.append(bilstm_valid_preds[i])\n",
    "std_preds = (np.array(std_preds))\n",
    "print(\"std valid acc:\", sum(std_preds == labels) / len(labels)) # std valid acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef4562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average on test dataset\n",
    "avg_preds = (electra_test_probs + bilstm_test_probs) * 0.5\n",
    "avg_preds = np.argmax(avg_preds, axis=1)\n",
    "print(\"avg valid acc:\", sum(avg_preds == labels) / len(labels)) # avg test acc\n",
    "\n",
    "# Confidence on test dataset\n",
    "conf_preds = []\n",
    "for i in range(len(labels)):\n",
    "    if np.max(electra_test_probs[i]) > np.max(bilstm_test_probs[i]):\n",
    "        conf_preds.append(electra_test_preds[i])\n",
    "    else:\n",
    "        conf_preds.append(bilstm_test_preds[i])\n",
    "conf_preds = (np.array(conf_preds))\n",
    "print(\"conf valid acc:\", sum(conf_preds == labels) / len(labels)) # conf test acc\n",
    "\n",
    "# Standard Deviation on test dataset\n",
    "std_preds = []\n",
    "for i in range(len(labels)):\n",
    "    if np.std(electra_test_probs[i]) > np.std(bilstm_test_probs[i]):\n",
    "        std_preds.append(electra_test_preds[i])\n",
    "    else:\n",
    "        std_preds.append(bilstm_test_preds[i])\n",
    "std_preds = (np.array(std_preds))\n",
    "print(\"std valid acc:\", sum(std_preds == labels) / len(labels)) # std test acc\n",
    "\n",
    "# Choice\n",
    "# submission_templete_df.Category = avg_preds\n",
    "# submission_templete_df.to_csv('./Submissions/avg_electra_bilstm_preds.csv', index=False)\n",
    "# submission_templete_df.Category = conf_preds\n",
    "# submission_templete_df.to_csv('./Submissions/conf_electra_bilstm_preds.csv', index=False)\n",
    "# submission_templete_df.Category = std_preds\n",
    "# submission_templete_df.to_csv('./Submissions/std_electra_bilstm_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7f7d7267",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T04:16:33.349723Z",
     "start_time": "2021-06-01T04:16:33.229164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg valid acc: 0.7717391304347826\n",
      "conf valid acc: 0.7711670480549199\n",
      "std valid acc: 0.7705949656750573\n"
     ]
    }
   ],
   "source": [
    "# Average on valid dataset\n",
    "avg_preds = (electra_valid_probs + bert_valid_probs) * 0.5\n",
    "avg_preds = np.argmax(avg_preds, axis=1)\n",
    "print(\"avg valid acc:\", sum(avg_preds == labels) / len(labels)) # avg valid acc\n",
    "\n",
    "# Confidence on valid dataset\n",
    "conf_preds = []\n",
    "for i in range(len(labels)):\n",
    "    if np.max(electra_valid_probs[i]) > np.max(bert_valid_probs[i]):\n",
    "        conf_preds.append(electra_valid_preds[i])\n",
    "    else:\n",
    "        conf_preds.append(bert_valid_preds[i])\n",
    "conf_preds = (np.array(conf_preds))\n",
    "print(\"conf valid acc:\", sum(conf_preds == labels) / len(labels)) # conf valid acc\n",
    "\n",
    "# Standard Deviation on valid dataset\n",
    "std_preds = []\n",
    "for i in range(len(labels)):\n",
    "    if np.std(electra_valid_probs[i]) > np.std(bert_valid_probs[i]):\n",
    "        std_preds.append(electra_valid_preds[i])\n",
    "    else:\n",
    "        std_preds.append(bert_valid_preds[i])\n",
    "std_preds = (np.array(std_preds))\n",
    "print(\"std valid acc:\", sum(std_preds == labels) / len(labels)) # std valid acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "010afd5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T04:17:04.671590Z",
     "start_time": "2021-06-01T04:17:04.662276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1, ..., 3, 4, 2])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average on test dataset\n",
    "avg_preds = (electra_test_probs + bert_test_probs) * 0.5\n",
    "avg_preds = np.argmax(avg_preds, axis=1)\n",
    "print(\"avg valid acc:\", sum(avg_preds == labels) / len(labels)) # avg test acc\n",
    "\n",
    "# Confidence on test dataset\n",
    "conf_preds = []\n",
    "for i in range(len(labels)):\n",
    "    if np.max(electra_test_probs[i]) > np.max(bert_test_probs[i]):\n",
    "        conf_preds.append(electra_test_preds[i])\n",
    "    else:\n",
    "        conf_preds.append(bert_test_preds[i])\n",
    "conf_preds = (np.array(conf_preds))\n",
    "print(\"conf valid acc:\", sum(conf_preds == labels) / len(labels)) # conf test acc\n",
    "\n",
    "# Standard Deviation on test dataset\n",
    "std_preds = []\n",
    "for i in range(len(labels)):\n",
    "    if np.std(electra_test_probs[i]) > np.std(bert_test_probs[i]):\n",
    "        std_preds.append(electra_test_preds[i])\n",
    "    else:\n",
    "        std_preds.append(bert_test_preds[i])\n",
    "std_preds = (np.array(std_preds))\n",
    "print(\"std valid acc:\", sum(std_preds == labels) / len(labels)) # std test acc\n",
    "\n",
    "# Choice\n",
    "# submission_templete_df.Category = avg_preds\n",
    "# submission_templete_df.to_csv('./Submissions/avg_electra_bert_preds.csv', index=False)\n",
    "# submission_templete_df.Category = conf_preds\n",
    "# submission_templete_df.to_csv('./Submissions/conf_electra_bert_preds.csv', index=False)\n",
    "# submission_templete_df.Category = std_preds\n",
    "# submission_templete_df.to_csv('./Submissions/std_electra_bert_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3f4539a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T02:50:49.653766Z",
     "start_time": "2021-06-01T02:50:49.530418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg valid acc: 0.6361556064073226\n",
      "conf valid acc: 0.6224256292906178\n",
      "std valid acc: 0.6189931350114416\n"
     ]
    }
   ],
   "source": [
    "# Average on valid dataset\n",
    "avg_preds = (bilstm_valid_probs + cnn_valid_probs) * 0.5\n",
    "avg_preds = np.argmax(avg_preds, axis=1)\n",
    "print(\"avg valid acc:\", sum(avg_preds == labels) / len(labels)) # avg valid acc\n",
    "\n",
    "# Confidence on valid dataset\n",
    "conf_preds = []\n",
    "for i in range(len(labels)):\n",
    "    if np.max(bilstm_valid_probs[i]) > np.max(cnn_valid_probs[i]):\n",
    "        conf_preds.append(bilstm_valid_preds[i])\n",
    "    else:\n",
    "        conf_preds.append(cnn_valid_preds[i])\n",
    "conf_preds = (np.array(conf_preds))\n",
    "print(\"conf valid acc:\", sum(conf_preds == labels) / len(labels)) # conf valid acc\n",
    "\n",
    "# Standard Deviation on valid dataset\n",
    "std_preds = []\n",
    "for i in range(len(labels)):\n",
    "    if np.std(bilstm_valid_probs[i]) > np.std(cnn_valid_probs[i]):\n",
    "        std_preds.append(bilstm_valid_preds[i])\n",
    "    else:\n",
    "        std_preds.append(cnn_valid_preds[i])\n",
    "std_preds = (np.array(std_preds))\n",
    "print(\"std valid acc:\", sum(std_preds == labels) / len(labels)) # std valid acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4afb482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average on test dataset\n",
    "avg_preds = (bilstm_test_probs + cnn_test_probs) * 0.5\n",
    "avg_preds = np.argmax(avg_preds, axis=1)\n",
    "print(\"avg valid acc:\", sum(avg_preds == labels) / len(labels)) # avg test acc\n",
    "\n",
    "# Confidence on test dataset\n",
    "conf_preds = []\n",
    "for i in range(len(labels)):\n",
    "    if np.max(bilstm_test_probs[i]) > np.max(cnn_test_probs[i]):\n",
    "        conf_preds.append(bilstm_test_preds[i])\n",
    "    else:\n",
    "        conf_preds.append(cnn_test_preds[i])\n",
    "conf_preds = (np.array(conf_preds))\n",
    "print(\"conf valid acc:\", sum(conf_preds == labels) / len(labels)) # conf test acc\n",
    "\n",
    "# Standard Deviation on test dataset\n",
    "std_preds = []\n",
    "for i in range(len(labels)):\n",
    "    if np.std(bilstm_test_probs[i]) > np.std(cnn_test_probs[i]):\n",
    "        std_preds.append(bilstm_test_preds[i])\n",
    "    else:\n",
    "        std_preds.append(cnn_test_preds[i])\n",
    "std_preds = (np.array(std_preds))\n",
    "print(\"std valid acc:\", sum(std_preds == labels) / len(labels)) # std test acc\n",
    "\n",
    "# Choice\n",
    "# submission_templete_df.Category = avg_preds\n",
    "# submission_templete_df.to_csv('./Submissions/avg_bilstm_cnn_preds.csv', index=False)\n",
    "# submission_templete_df.Category = conf_preds\n",
    "# submission_templete_df.to_csv('./Submissions/conf_bilstm_cnn_preds.csv', index=False)\n",
    "# submission_templete_df.Category = std_preds\n",
    "# submission_templete_df.to_csv('./Submissions/std_bilstm_cnn_preds.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}