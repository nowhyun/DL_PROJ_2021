{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sensitive-registration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training device: (device(type='cuda', index=0), 'GeForce GTX 1660 Ti')\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.style.use(\"ggplot\")\n",
    "\n",
    "from Utils.dataset import *\n",
    "from Utils.utils import *\n",
    "from Models.BertClf import *\n",
    "from Models.LstmClf import *\n",
    "from Models.ElectraClf import *\n",
    "device = torch.device(\"cuda:\" + str(0)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'training device: {device, torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-willow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "infectious-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define signature\n",
    "signature = \"jh_BILSTM_6M_1D_15H_10M\"_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "liable-incidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define signature\n",
    "signature = \"jh_BERT_6M_1D_20H_8M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "enabling-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define signature   ----> 수정 필요\n",
    "#signature = \"jh_ELECTRA_5M_31D_17H_5M\"\n",
    "signature = \"sw_focal_ELECTRA_6M_1D_18H_48M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "recent-costa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(aug=0, author='sw_focal', batch_size=16, data_path='./Dataset', dropout=0.5, embedding_dim=256, eps=1e-08, freeze_pretrained=0, gpu=0, hidden_dim=768, kernel_depth=500, kernel_sizes=[3, 4, 5], lr_clf=0.0001, lr_pretrained=1e-05, max_epoch=30, max_len=50, model='ELECTRA', num_layer=2, save=1, save_model_path='./Saved_models', save_submission_path='./Submissions', sent_embedding=0, signature='sw_focal_ELECTRA_6M_1D_18H_48M', split_ratio=1, weight_decay=0.0005)\n"
     ]
    }
   ],
   "source": [
    "# Load options\n",
    "parser = argparse.ArgumentParser()\n",
    "#     opt = parser.parse_args() # in .py env\n",
    "opt, _ = parser.parse_known_args() # in .ipynb env\n",
    "with open('./Saved_models/' + signature + '_opt.txt', 'r') as f:\n",
    "    opt.__dict__ = json.load(f)\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "continuing-columbus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data...\n",
      "Apply the ElectraTokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_X_ids_tsr.shape: torch.Size([1748, 50])\n",
      "valid_X_masks_tsr.shape: torch.Size([1748, 50])\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = ValidDataset(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "enormous-makeup",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataloader = DataLoader(valid_dataset,batch_size=opt.batch_size,shuffle=False)\n",
    "#len(valid_dataset)opt.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "hidden-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load untrained model\n",
    "if opt.model == \"BERT\":\n",
    "    model = BertClassifier(opt).to(device)\n",
    "elif opt.model == \"ELECTRA\":\n",
    "    model = ElectraClassifier(opt).to(device)\n",
    "elif opt.model == \"BILSTM\":\n",
    "    model = LstmClassifier(opt,30522).to(device)\n",
    "elif opt.model =='ConvClassifier':\n",
    "    model = ConvClassifier(opt,30522).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cooked-application",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraClassifier(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=768, out_features=5, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load trained model\n",
    "model_save_path = str(opt.save_model_path) + \"/\" + opt.signature +'.model'\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cross-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_logits = []\n",
    "all_label=[]\n",
    "for batch in valid_dataloader:\n",
    "    # Load batch to GPU\n",
    "    b_ids_tsr, b_masks_tsr, b_label_tsr = tuple(tsr.to(device) for tsr in batch)\n",
    "    with torch.no_grad():\n",
    "        if opt.model in [\"BILSTM\", \"CNN\"]:\n",
    "            logits = model(b_ids_tsr)\n",
    "        else:\n",
    "            logits = model(b_ids_tsr, b_masks_tsr)\n",
    "    all_logits.append(logits)\n",
    "    all_label.append(b_label_tsr)\n",
    "all_logits = torch.cat(all_logits, dim=0)\n",
    "all_label = torch.cat(all_label, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "wooden-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply softmax to calculate probabilities\n",
    "probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
    "preds = np.argmax(probs, axis=1)\n",
    "valid_dataset.df['Pred']=preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "improving-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the predict\n",
    "if opt.model == \"BERT\":\n",
    "    valid_dataset.df.to_csv('./Dataset/BERT_pred.csv',index=False)\n",
    "    #np.save('./Dataset/BERT_pred',preds)\n",
    "elif opt.model == \"ELECTRA\":\n",
    "    valid_dataset.df.to_csv('./Dataset/ELECTRA_pred_1.csv',index=False)\n",
    "    #np.save('./Dataset/ELECTRA_pred',preds)\n",
    "elif opt.model == \"BILSTM\":\n",
    "    valid_dataset.df.to_csv('./Dataset/BILSTM_pred.csv',index=False)\n",
    "    #np.save('./Dataset/BILSTM_pred',preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-rebound",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "funny-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert = pd.read_csv('./Dataset/BERT_pred.csv')\n",
    "df_electra=pd.read_csv('./Dataset/ELECTRA_pred.csv')\n",
    "df_bilstm=pd.read_csv('./Dataset/BILSTM_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "linear-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert.rename(columns = {'Pred': 'b_pred'}, inplace = True)\n",
    "df_electra.rename(columns = {'Pred': 'e_pred'}, inplace = True)\n",
    "df_bilstm.rename(columns = {'Pred': 'l_pred'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "limiting-initial",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_bert_electra=pd.merge(df_bert,df_electra,how='inner',on=['Sentence','Category','Id'])\n",
    "merge_total=pd.merge(merge_bert_electra,df_bilstm,how='inner',on=['Sentence','Category','Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-soviet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "focal-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "## electra는 맞히는데 bilstm은 못 맞히는거\n",
    "merge_t_f=merge_total[merge_total['e_pred']==merge_total['Category']] ##bert와 electra가 맞힌 경우\n",
    "merge_t_f=merge_t_f[merge_t_f['l_pred']!=merge_t_f['Category']] ##bilstm가 못 맞힌 경우\n",
    "merge_t_f.to_csv('./Dataset/ELECTRA_CORRECT.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "resistant-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "## electra는 못 맞히는데 bilstm은 맞히는거\n",
    "merge_f_t=merge_total[merge_total['e_pred']!=merge_total['Category']] ##bert와 electra가 못맞힌 경우\n",
    "merge_f_t=merge_f_t[merge_f_t['l_pred']==merge_f_t['Category']] ##bilstm이 밎힌 경우\n",
    "merge_f_t.to_csv('./Dataset/BILSTM_CORRECT.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-inspiration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "possible-logistics",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## bert와 electra는 맞히는데 bilstm은 못 맞히는거\n",
    "merge_t_f=merge_total[merge_total['b_pred']==merge_total['e_pred']] ## bert와 electra 예측 같은 경우\n",
    "merge_t_f=merge_t_f[merge_t_f['b_pred']==merge_t_f['Category']] ##bert와 electra가 맞힌 경우\n",
    "merge_t_f=merge_t_f[merge_t_f['l_pred']!=merge_t_f['Category']] ##bilstm가 못 맞힌 경우\n",
    "merge_t_f.to_csv('./Dataset/BERT_ELECTRA_CORRECT.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "neither-trustee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bert와 electra, bilstm은 모두 맞히는거\n",
    "merge_t_t=merge_total[merge_total['b_pred']==merge_total['e_pred']] ## bert와 electra 예측 같은 경우\n",
    "merge_t_t=merge_t_t[merge_t_t['b_pred']==merge_t_t['Category']] ##bert와 electra가 맞힌 경우\n",
    "merge_t_t=merge_t_t[merge_t_t['l_pred']==merge_t_t['Category']] ##bilstm도 맞힌 경우\n",
    "merge_t_t.to_csv('./Dataset/BERT_ELECTRA_BILSTM_CORRECT.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "outstanding-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bert와 electra는 못 맞히는데 bilstm은 맞히는거\n",
    "merge_f_t=merge_total[merge_total['b_pred']==merge_total['e_pred']] ## bert와 electra 예측 같은 경우\n",
    "merge_f_t=merge_f_t[merge_f_t['b_pred']!=merge_f_t['Category']] ##bert와 electra가 못맞힌 경우\n",
    "merge_f_t=merge_f_t[merge_f_t['l_pred']==merge_f_t['Category']] ##bilstm이 밎힌 경우\n",
    "merge_f_t.to_csv('./Dataset/BILSTM_CORRECT.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-relation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-wisdom",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-hardware",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-strengthening",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset_df = pd.read_csv(opt.data_path +'/valid_dd_ratio_' + str(opt.split_ratio) + '.csv')\n",
    "valid_X_arr = valid_dataset_df.Sentence.values\n",
    "valid_y_arr = valid_dataset_df.Category.values\n",
    "## validdataset class에 dataframe 저장되게 해도 된다.\n",
    "valid_X_ids_tsr, valid_X_masks_tsr = preprocessing_for_bert(valid_X_arr, opt)\n",
    "ids_tsr = valid_X_ids_tsr\n",
    "masks_tsr = valid_X_masks_tsr\n",
    "labels = torch.LongTensor(valid_y_arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
