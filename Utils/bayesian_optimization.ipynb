{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "communist-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bayeso import covariance\n",
    "from bayeso.gp import gp\n",
    "from bayeso.utils import utils_covariance\n",
    "from bayeso.utils import utils_plotting\n",
    "from bayeso.utils import utils_common\n",
    "from bayeso import acquisition\n",
    "import numpy as np\n",
    "\n",
    "from bayeso import bo\n",
    "from bayeso.wrappers import wrappers_bo\n",
    "from bayeso.utils import utils_plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "internal-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn,optim\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.transforms import Compose, ToTensor, RandomCrop, RandomRotation, Normalize\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "characteristic-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_parameter_tunning(learning_rate,hidden_layer_size,epoch_num, batch_num, early_stop_thr,train_loader,val_loader):\n",
    "    net = nn.Sequential(\n",
    "    nn.Linear(28*28,hidden_layer_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_layer_size,10)\n",
    "    ).to(device)\n",
    "    optimizer = optim.SGD(net.parameters(),lr=learning_rate,weight_decay=0)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    \n",
    "    epoch_list=[]\n",
    "    val_accuracy_list=[]\n",
    "    best_val=0\n",
    "    state=0\n",
    "    total_num = batch_num\n",
    "    \n",
    "    net.train()\n",
    "    \n",
    "    for epoch in range(epoch_num):\n",
    "        for i,(train_x,train_y) in enumerate(train_loader):\n",
    "            train_x = train_x.view(-1, 28 * 28).to(device)\n",
    "            train_y = train_y.to(device)\n",
    "            y_pred = net(train_x)\n",
    "            loss = loss_function(y_pred,train_y.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        epoch_list.append(epoch+1)\n",
    "        \n",
    "        net.eval()\n",
    "        for j,(val_x,val_y) in enumerate(val_loader):\n",
    "            if j>0:\n",
    "                break\n",
    "            val_x = val_x.view(-1, 28 * 28).float().to(device)\n",
    "            val_y = val_y.to(device)\n",
    "            y_pred = net(val_x)\n",
    "            _,y_class = torch.max(y_pred, 1)\n",
    "            correct_num = (val_y == y_class).sum()\n",
    "            val_accuracy = correct_num.cpu().numpy() / total_num *100\n",
    "            val_accuracy_list.append(val_accuracy)\n",
    "            \n",
    "            if val_accuracy >best_val:\n",
    "                state=0\n",
    "                best_val=val_accuracy\n",
    "            else:\n",
    "                state+=1\n",
    "        if state>=early_stop_thr:\n",
    "            break\n",
    "\n",
    "    return best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "suburban-charger",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO-wrappers_bo-05/27/2021-10:30:17] range_X:\n",
      "[[0.010, 0.050],\n",
      "[128.000, 512.000]]\n",
      "[INFO-wrappers_bo-05/27/2021-10:30:17] str_cov: se\n",
      "[INFO-wrappers_bo-05/27/2021-10:30:17] str_acq: ei\n",
      "[INFO-wrappers_bo-05/27/2021-10:30:17] str_optimizer_method_gp: BFGS\n",
      "[INFO-wrappers_bo-05/27/2021-10:30:17] str_optimizer_method_bo: L-BFGS-B\n",
      "[INFO-wrappers_bo-05/27/2021-10:30:17] str_modelselection_method: ml\n",
      "[INFO-wrappers_bo-05/27/2021-10:30:17] num_init: 3\n",
      "[INFO-wrappers_bo-05/27/2021-10:30:17] num_iter: 20\n",
      "[INFO-wrappers_bo-05/27/2021-10:30:17] str_initial_method_bo: sobol\n",
      "[INFO-wrappers_bo-05/27/2021-10:30:17] str_sampling_method_ao: sobol\n",
      "[INFO-wrappers_bo-05/27/2021-10:30:17] num_samples_ao: 100\n",
      "[INFO-wrappers_bo-05/27/2021-10:30:17] str_mlm_method: regular\n",
      "[INFO-wrappers_bo-05/27/2021-10:30:17] seed: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BO Round 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO-wrappers_bo-05/27/2021-10:33:56] Iteration 1\n",
      "[INFO-wrappers_bo-05/27/2021-10:35:06] Iteration 2\n",
      "[INFO-wrappers_bo-05/27/2021-10:36:50] Iteration 3\n",
      "[INFO-wrappers_bo-05/27/2021-10:37:41] Iteration 4\n",
      "[INFO-wrappers_bo-05/27/2021-10:39:01] Iteration 5\n",
      "[INFO-wrappers_bo-05/27/2021-10:39:59] Iteration 6\n",
      "[INFO-wrappers_bo-05/27/2021-10:41:05] Iteration 7\n",
      "[INFO-wrappers_bo-05/27/2021-10:41:55] Iteration 8\n",
      "[INFO-wrappers_bo-05/27/2021-10:42:42] Iteration 9\n",
      "[INFO-wrappers_bo-05/27/2021-10:43:44] Iteration 10\n",
      "[INFO-wrappers_bo-05/27/2021-10:44:50] Iteration 11\n",
      "[INFO-wrappers_bo-05/27/2021-10:46:23] Iteration 12\n",
      "[INFO-wrappers_bo-05/27/2021-10:47:29] Iteration 13\n",
      "[INFO-wrappers_bo-05/27/2021-10:49:02] Iteration 14\n",
      "[INFO-wrappers_bo-05/27/2021-10:50:58] Iteration 15\n",
      "[INFO-wrappers_bo-05/27/2021-10:52:03] Iteration 16\n",
      "[INFO-wrappers_bo-05/27/2021-10:53:21] Iteration 17\n",
      "[INFO-wrappers_bo-05/27/2021-10:55:02] Iteration 18\n",
      "[INFO-wrappers_bo-05/27/2021-10:57:02] Iteration 19\n",
      "[INFO-wrappers_bo-05/27/2021-10:57:53] Iteration 20\n"
     ]
    }
   ],
   "source": [
    "#num_points = 1000\n",
    "str_cov = 'se'\n",
    "#num_iter = 20\n",
    "#num_ts = 5\n",
    "\n",
    "list_Y_min = []\n",
    "\n",
    "\"\"\"\n",
    "bounds = np.array([[0,10],[0,10]])  ##define 필요\n",
    "\n",
    "def fun_target(X): ##define 필요\n",
    "    return X[0]+X[1]\n",
    "\"\"\"\n",
    "bounds = np.array([[0.01,0.05],[128,512]])  ##define 필요\n",
    "\n",
    "def fun_target(X): ##define 필요\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
    "    mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=ToTensor())\n",
    "    mnist_train, mnist_val = torch.utils.data.random_split(mnist_trainset, [int(len(mnist_trainset)/6*5), int(len(mnist_trainset)/6)])\n",
    "    batch_num=512\n",
    "    train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_num,shuffle=True, num_workers=2, drop_last = True)\n",
    "    val_loader = torch.utils.data.DataLoader(mnist_val, batch_size=batch_num,shuffle=True, num_workers=2, drop_last = True)\n",
    "    \n",
    "    \n",
    "    return hyper_parameter_tunning(int(X[0]),int(X[1]), 512, 50,10,train_loader,val_loader)\n",
    "\n",
    "\n",
    "cur_regret_list =[]\n",
    "X_list =[]\n",
    "Y_list =[]\n",
    "# str_cov_list = ['se', 'matern32', 'matern52']\n",
    "str_cov_list = ['se']\n",
    "\n",
    "for str_cov in str_cov_list:\n",
    "    #num_bo = 3\n",
    "    num_bo = 1\n",
    "    #str_cov = 'se'\n",
    "    num_iter = 20\n",
    "    num_init = 3\n",
    "\n",
    "    model_bo = bo.BO(bounds, debug=False,str_cov = str_cov)\n",
    "    list_Y = []\n",
    "    list_time = []\n",
    "\n",
    "    for ind_bo in range(0, num_bo):\n",
    "        print('BO Round', ind_bo + 1)\n",
    "        #X_final, Y_final, time_final, _, _ = wrappers_bo.run_single_round(model_bo, fun_target, num_init, num_iter,str_initial_method_bo='uniform', str_sampling_method_ao='uniform', num_samples_ao=100,seed=42 * ind_bo)\n",
    "        X_final, Y_final, time_final, _, _ = wrappers_bo.run_single_round(model_bo, fun_target, num_init, num_iter,str_initial_method_bo='sobol', str_sampling_method_ao='sobol', num_samples_ao=100,seed=42 * ind_bo)\n",
    "\n",
    "        list_Y.append(Y_final)\n",
    "        list_time.append(time_final)\n",
    "\n",
    "    arr_Y = np.array(list_Y)\n",
    "    arr_time = np.array(list_time)\n",
    "\n",
    "    X_list.append(X_final)\n",
    "    Y_list.append(Y_final)\n",
    "\n",
    "    arr_Y = np.expand_dims(np.squeeze(arr_Y), axis=0)\n",
    "    arr_time = np.expand_dims(arr_time, axis=0)\n",
    "    \n",
    "    \"\"\"num_bo>1 때 plot 그려줌\n",
    "    utils_plotting.plot_minimum_vs_iter(arr_Y, [str_fun], num_init, True,\n",
    "        use_tex=True,\n",
    "        str_x_axis=r'\\textrm{Iteration}',\n",
    "        str_y_axis=r'\\textrm{Mininum function value}')\n",
    "    utils_plotting.plot_minimum_vs_time(arr_time, arr_Y, [str_fun], num_init, True,\n",
    "        use_tex=True,\n",
    "        str_x_axis=r'\\textrm{Time (sec.)}',\n",
    "        str_y_axis=r'\\textrm{Mininum function value}')\n",
    "    regret = [[np.min(arr_Y[0,k,:(i+1)])-np.min(arr_Y) for i in range(arr_Y.shape[2])] for k in range(arr_Y.shape[1])]\n",
    "    regret = np.array(regret)\n",
    "    sum_regret = np.sum(regret)\n",
    "    cur_regret_list.append(sum_regret)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "#mu_, sigma_, Sigma_ = gp.predict_with_optimized_hyps(X_final, Y_final, X_test, str_cov=str_cov)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
